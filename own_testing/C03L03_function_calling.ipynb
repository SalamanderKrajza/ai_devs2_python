{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function calling\n",
    "#### **General idea**\n",
    "Let LLM know how to prepare its output so it can be used by your functions\n",
    "\n",
    "\n",
    "#### **Explanation**\n",
    "LLM can't execute any functions by itself, but if its object is initialized in right way it may\n",
    "1. Get list of functions that may be executed with his output\n",
    "2. Get list of desired input for each function\n",
    "3. Choose which function from your list is best fit to your prompt\n",
    "4. Prepare its result in json fromat that may be passed to function later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets start with some smple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of elephants is 1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_elephants(some_str, case_sensitive=False, output_format=\"num\"):\n",
    "    \"\"\"\n",
    "    It counts ELEPHANTS in given text\n",
    "    INPUTS:\n",
    "    some_str: str - Extracted part of user message that contains text to count elephants\n",
    "    case_sensitive: bool - True if user specifies he want to counts only SMALL or BIG elephants or if he expectly mentiond it should be case sensitive\n",
    "    output_format: str - [\"num\", \"text]\" - num (if user ask for counting elephants) text (if user ask to tell him how many elephants)\n",
    "    \"\"\"\n",
    "    if not case_sensitive:\n",
    "        some_str = some_str.lower()\n",
    "    cnt = len(some_str.split(\"elephant\"))-1\n",
    "    if output_format == \"num\": \n",
    "        return cnt\n",
    "    else:\n",
    "        return f\"Number of elephants is {cnt}\"\n",
    "\n",
    "count_elephants(\n",
    "    \"In this text we have John - The BIG ELEPHANT, and Susan, the little elephant\", \n",
    "    case_sensitive=True, output_format=\"text\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing function schema and passing it to LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_elephants_schema = {\n",
    "    \"name\": \"count_elephants\",\n",
    "    \"description\": \"Counts elephants in some text provided by user\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"some_str\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Extracted part of user message that contains text to count elephants\",\n",
    "            },\n",
    "            \"case_sensitive\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"True if user specifies he want to counts only SMALL or BIG elephants or if he expectly mentiond it should be case sensitive\"\n",
    "            },\n",
    "            \"output_format\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"num (if user ask for counting elephants) text (if user ask to tell him how many elephants)\",\n",
    "                \"enum\": [\"num\", \"text\"]\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"some_str\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**initialization model with funcitons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# WITHOUT FUNCTION_CALL SPECIFIED (which indicates default function)\n",
    "# --------------------------------------------------------------\n",
    "# Model will respond normally (without functions) unless function use would be obvvious\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "model_with_functions = ChatOpenAI(\n",
    "    model_name=\"gpt-4-0613\",\n",
    "    model_kwargs={\n",
    "        \"functions\": [count_elephants_schema]\n",
    "        # \"function_call\": {\"name\": \"query_enrichment\"}, \n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_with_functions response for non-related to elephants stuff (no function_call specified)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"Hello! How can I assist you today?\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 10,\n",
      "            \"prompt_tokens\": 131,\n",
      "            \"total_tokens\": 141\n",
      "        },\n",
      "        \"model_name\": \"gpt-4-0613\",\n",
      "        \"system_fingerprint\": null,\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run-e2faf76d-ebec-4a29-9799-2bf9b1a68df5-0\",\n",
      "    \"example\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "result = model_with_functions.invoke([HumanMessage(content=\"Hey there!\")])\n",
    "print(json.dumps(json.loads(result.json()), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_with_functions response for asking to count elephants (no function_call specified)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"\",\n",
      "    \"additional_kwargs\": {\n",
      "        \"function_call\": {\n",
      "            \"arguments\": \"{\\n  \\\"some_str\\\": \\\"Elephants? I love elephants! Elephants are fucking amazing!\\\",\\n  \\\"output_format\\\": \\\"num\\\"\\n}\",\n",
      "            \"name\": \"count_elephants\"\n",
      "        }\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 36,\n",
      "            \"prompt_tokens\": 149,\n",
      "            \"total_tokens\": 185\n",
      "        },\n",
      "        \"model_name\": \"gpt-4-0613\",\n",
      "        \"system_fingerprint\": null,\n",
      "        \"finish_reason\": \"function_call\",\n",
      "        \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run-fe234ea4-89bc-4327-b17e-f1adee3d0829-0\",\n",
      "    \"example\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "result = model_with_functions.invoke(\n",
    "    [\n",
    "        HumanMessage(content='Please, count elephants in the text \"Elephants? I love elephants! Elephants are fucking amazing!')\n",
    "    ]\n",
    ")\n",
    "print(json.dumps(json.loads(result.json()), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_with_functions response for non-related to elephants stuff (WITH function_call specified)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"\",\n",
      "    \"additional_kwargs\": {\n",
      "        \"function_call\": {\n",
      "            \"arguments\": \"{\\n  \\\"some_str\\\": \\\"Hey there!\\\"\\n}\",\n",
      "            \"name\": \"count_elephants\"\n",
      "        }\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 11,\n",
      "            \"prompt_tokens\": 138,\n",
      "            \"total_tokens\": 149\n",
      "        },\n",
      "        \"model_name\": \"gpt-4-0613\",\n",
      "        \"system_fingerprint\": null,\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run-d3902e91-3418-4060-bbde-9bb9b2ad8158-0\",\n",
      "    \"example\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# WITH FUNCTION_CALL SPECIFIED (default = count_elaphants)\n",
    "# --------------------------------------------------------------\n",
    "# (model will choose this if context not suggest any other from list)\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_with_functions = ChatOpenAI(\n",
    "    model_name=\"gpt-4-0613\",\n",
    "    model_kwargs={\n",
    "        \"functions\": [count_elephants_schema],\n",
    "        \"function_call\": {\"name\": \"count_elephants\"}, \n",
    "    }\n",
    ")\n",
    "\n",
    "import json\n",
    "result = model_with_functions.invoke([HumanMessage(content=\"Hey there!\")])\n",
    "print(json.dumps(json.loads(result.json()), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using python BaseModel and pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining pydantic BaseModel to let LLM know about structure**\n",
    "\n",
    "```\n",
    "NOTE: There is STR value in output_format instead of ENUM. \n",
    "Using ENUM here requires Enum library and defining new class\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CountElephantsInput(BaseModel):\n",
    "    some_str: str = Field(..., description=\"Extracted part of user message that contains text to count elephants\")\n",
    "    case_sensitive: bool = Field(False, description=\"True if user specifies he want to counts only SMALL or BIG elephants or if he expectly mentiond it should be case sensitive\")\n",
    "    output_format: str = Field(\"num\", description=\"num (if user ask for counting elephants) text (if user ask to tell him how many elephants)\")\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"some_str\": \"There are 5 elephants in the room, and 2 more elephants just entered.\",\n",
    "                \"case_sensitive\": False,\n",
    "                \"output_format\": \"text\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize model with functions schema defined with pydantic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChatOpenAI with the bound function\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4-0613\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "model_with_functions_pydantic = model.bind_functions(\n",
    "    functions=[CountElephantsInput],\n",
    "    function_call={\"name\": \"CountElephantsInput\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_with_functions_pydantic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"\",\n",
      "    \"additional_kwargs\": {\n",
      "        \"function_call\": {\n",
      "            \"arguments\": \"{\\n  \\\"some_str\\\": \\\"this is elephant, this is another elephant so we have two of them, right?\\\"\\n}\",\n",
      "            \"name\": \"CountElephantsInput\"\n",
      "        }\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 25,\n",
      "            \"prompt_tokens\": 161,\n",
      "            \"total_tokens\": 186\n",
      "        },\n",
      "        \"model_name\": \"gpt-4-0613\",\n",
      "        \"system_fingerprint\": null,\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run-a119ae15-9c22-4e62-84df-0dd55e596858-0\",\n",
      "    \"example\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hey there! Lets count elephants in just single example: 'this is elephant, this is another elephant so we have two of them, right?'\"\n",
    "result = model_with_functions_pydantic.invoke([HumanMessage(content=user_input)])\n",
    "print(json.dumps(json.loads(result.json()), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROS OF PYDANTIC - we can easly test model outpus against defined class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountElephantsInput\n",
      "{\n",
      "  \"some_str\": \"this is elephant, this is another elephant so we have two of them, right?\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountElephantsInput(some_str='this is elephant, this is another elephant so we have two of them, right?', case_sensitive=False, output_format='num')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets take previous example function args\n",
    "function_name = result.additional_kwargs[\"function_call\"][\"name\"]\n",
    "print(function_name)\n",
    "\n",
    "function_args = result.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "print(function_args)\n",
    "\n",
    "# Lets validate&parse it\n",
    "validated_args = CountElephantsInput.parse_raw(function_args)\n",
    "validated_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"some_str\": \"Hey there!\", \"case_sensitive\": \"it should be boolean\"}\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for CountElephantsInput\ncase_sensitive\n  value could not be parsed to a boolean (type=type_error.bool)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22456/4228844251.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Lets validate&parse it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvalidated_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountElephantsInput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_valid_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mvalidated_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\salamander\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\main.cp310-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.parse_raw\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\salamander\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\main.cp310-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.parse_obj\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\salamander\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\main.cp310-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for CountElephantsInput\ncase_sensitive\n  value could not be parsed to a boolean (type=type_error.bool)"
     ]
    }
   ],
   "source": [
    "non_valid_args ='{\"some_str\": \"Hey there!\", \"case_sensitive\": \"it should be boolean\"}'\n",
    "print(non_valid_args)\n",
    "\n",
    "# Lets validate&parse it\n",
    "validated_args = CountElephantsInput.parse_raw(non_valid_args)\n",
    "validated_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting fucnname & kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> count_elephants\n",
      "<class 'dict'> {'some_str': 'Elephants? I love elephants! Elephants are fucking amazing!'}\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Extract from model.invoke([])\n",
    "# --------------------------------------------------------------\n",
    "result = model_with_functions.invoke([ HumanMessage(content='Please, count elephants in the text \"Elephants? I love elephants! Elephants are fucking amazing!')])\n",
    "function_name = result.additional_kwargs[\"function_call\"][\"name\"]\n",
    "function_args = json.loads(result.additional_kwargs[\"function_call\"][\"arguments\"])\n",
    "print(type(function_name), function_name)\n",
    "print(type(function_args), function_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> count_elephants\n",
      "<class 'dict'> {'some_str': 'Elephants? I love elephants! Elephants are fucking amazing!', 'output_format': 'text'}\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Extract from model.agenerate([[]])\n",
    "# --------------------------------------------------------------\n",
    "result = await model_with_functions.agenerate([[HumanMessage(content='Please, count elephants in the text \"Elephants? I love elephants! Elephants are fucking amazing!')]])\n",
    "\n",
    "result_dict = result.generations[0][0].dict()\n",
    "function_call_data = result_dict['message']['additional_kwargs']['function_call']\n",
    "function_name = function_call_data['name']\n",
    "function_args = json.loads(function_call_data['arguments'])\n",
    "print(type(function_name), function_name)\n",
    "print(type(function_args), function_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_elephants {\n",
      "    \"some_str\": \"this is elephant, this is another elephant so we have two of them, right?\",\n",
      "    \"case_sensitive\": false,\n",
      "    \"output_format\": \"num\"\n",
      "}\n",
      "\n",
      "\n",
      "Result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define list of functions available to model\n",
    "function_mapping = {'count_elephants':count_elephants}\n",
    "\n",
    "# Our function have not defined validation inside it so lets assume we validate args before passing it\n",
    "# For this example i will pick values from Pydantic validation example\n",
    "function_name = function_name\n",
    "function_kwargs = validated_args.dict()\n",
    "print(function_name, json.dumps(function_kwargs,indent=4))\n",
    "\n",
    "# Execute function\n",
    "print(\"\\n\\nResult:\")\n",
    "function_mapping[function_name](**function_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function_calling vs prompt_with_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In task C04L01 we have to clasify user input to either - request directy by LLM or ask some API for response\n",
    "\n",
    "My attempt was to create function schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"question\":\"Czy złotówka jest droższa od euro?\",\"knowledge_source\":\"currency\",\"currency\":\"PLN\",\"answer\":\"Złotówka jest tańsza od euro.\"}', 'name': 'select_source'}}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 183, 'total_tokens': 227}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-51ae87ed-4653-4b23-9e3c-72597217b55e-0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_source_schema = {\n",
    "    \"name\": \"select_source\",\n",
    "    \"description\": \"Select knowledge source from specified list basing on question content\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Unchanged user question\"\n",
    "            },\n",
    "            \"knowledge_source\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"currency (if user ask exhange rates) population (if user asks about population of the country), other (otherwise)\",\n",
    "                \"enum\": [\"currency\", \"population\", \"general\"]\n",
    "            },\n",
    "            \"currency\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"3-digits Code for specific currency, f.e USD, PLN, EUR\",\n",
    "            },\n",
    "            \"country\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of country from question in English, f.e Poland, Germany, United Kingdo\",\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Answer for user question. Required if knowledge_source is 'general'\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"knowledge_source\", \"question\", \"answer\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_with_functions = ChatOpenAI(\n",
    "    # model_name=\"gpt-4-0613\",\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    model_kwargs={\n",
    "        \"functions\": [select_source_schema],\n",
    "        \"function_call\": {\"name\": \"select_source\"}, \n",
    "    }\n",
    ")\n",
    "\n",
    "result = model_with_functions.invoke([HumanMessage('Czy złotówka jest droższa od euro?')])\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile the alternative mentioned by one other person in course was just using prompt with examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\"question_type\": \"general\", \"answer\": \"Nie, obecnie złotówka jest tańsza od euro.\"}', response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 161, 'total_tokens': 190}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-2faa626f-538b-48a9-984d-01150c8ee0bb-0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     'I classify questions and extract needed data for question in json form. '\n",
    "     'On questions about population I only return country name. '\n",
    "     'On questions about currency rate I return only country code. '\n",
    "     'For other question I try response in answer field. For example:\\n'\n",
    "     'Q: Jaka jest populacja Węgier?\\n'\n",
    "     'A: {{\"question_type\": \"population\", \"country_name\": \"Hungary\"}}\\n'\n",
    "     'Q: Jaki jest teraz kurs Forinta?\\n'\n",
    "     'A: {{\"question_type\": \"currency\", \"currency_code\": \"HUF\"}}\\n'\n",
    "     'Q: Kto to jest Adam Małysz?\\n'\n",
    "     'A: {{\"question_type\": \"general\", \"answer\": \"Skoczek narciarski\"}}\\n'),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "result = chain.invoke({\"question\": 'Czy złotówka jest droższa od euro?'})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both variants works perfectly well on examples provided with task and solved it with 100% accuracy.\n",
    "\n",
    "I made some tests about using different questions (close to provided in task samples but with different results wanted)\n",
    "\n",
    "I will quote myself from forum disscusions about this\n",
    "\n",
    "### Quote from forum\n",
    "Zrobiłem pare testów, na zasadzie \"pytanie podobne do tego z puli, ale jednak inne\":\n",
    "\n",
    "`Ile ludzi mieszka w Augustowie;`\n",
    "\n",
    "__**Dla modelu GPT-3**__\n",
    "\n",
    "- z function_calling zwraca: \"population\" z Polską jako krajem ORAZ answerem z poprawną odpowiedzią❌\n",
    "\n",
    "- bez function_calling zwraca: \"population\" z Polską jako krajem ❌\n",
    "\n",
    "__**Dla modelu GPT-4**__\n",
    "\n",
    "- z function_calling zwraca: \"general\" z odpowiedzią ✅\n",
    "\n",
    "- bez function_calling zwraca: 'population', 'poland' ❌\n",
    "\n",
    "\n",
    "`Czy złotówki są droższe od euro?`\n",
    "\n",
    "__**Dla modelu GPT-3**__\n",
    "\n",
    "- z function_calling zwraca: \"general\" i \"Złotówki są tańsze od euro.\" ✅\n",
    "\n",
    "- bez function_calling zwraca: \"general\" i informacje żeby sobie sprawdzić kursy wymiany walut ✅/❌\n",
    "\n",
    "__**Dla modelu GPT-4**__\n",
    "\n",
    "- z function_calling zwraca: \"general\" z poprawną odpowiedią ✅\n",
    "\n",
    "- bez function_calling zwraca \"currency\", \"PLN\" ✅\n",
    "\n",
    "\n",
    "Także wydaje się, że przy używaniu wersji 4rtej lepiej sobie radzi z pytaniami podobnymi, ale z drugiej strony mój prompt był dużo bardziej szczegółówo opisany więc nie wiem czy to zasługa użycia function_calling czy więcej czasu poświęciłem na opisanie poszczególnych pól.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get schema from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"multiply\",\n",
      "    \"description\": \"Multiply two integers together.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"First integer\"\n",
      "        },\n",
      "        \"b\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"Second integer\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"a\",\n",
      "        \"b\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example from https://python.langchain.com/docs/modules/model_io/chat/function_calling/\n",
    "import json\n",
    "\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "print(json.dumps(convert_to_openai_tool(multiply), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets test with orginal function (NOT TYPES SPECIFIED) - not working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"count_elephants\",\n",
      "    \"description\": \"It counts ELEPHANTS in given text\\nINPUTS:\\nsome_str: str - text that we use to count elephants\\ncase_sensitive: bool - \\noutput_format: str - [\\\"num\\\", \\\"text]\\\" - to present implementation enum in function_calling\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {},\n",
      "      \"required\": [\n",
      "        \"some_str\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "def count_elephants(some_str, case_sensitive=False, output_format=\"num\"):\n",
    "    \"\"\"\n",
    "    It counts ELEPHANTS in given text\n",
    "    INPUTS:\n",
    "    some_str: str - text that we use to count elephants\n",
    "    case_sensitive: bool - \n",
    "    output_format: str - [\"num\", \"text]\" - to present implementation enum in function_calling\n",
    "    \"\"\"\n",
    "    if not case_sensitive:\n",
    "        some_str = some_str.lower()\n",
    "    cnt = len(some_str.split(\"elephant\"))-1\n",
    "    if output_format == \"num\": \n",
    "        return cnt\n",
    "    else:\n",
    "        return f\"Number of elephants is {cnt}\"\n",
    "    \n",
    "print(json.dumps(convert_to_openai_tool(count_elephants), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improved functions (Types specified and variables description)\n",
    "**NOTE: I wasn't able to make ENUM works here, however we can add this manualy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"count_elephants\",\n",
      "    \"description\": \"Counts elephants in some text provided by user\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"some_str\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Extracted part of user message that contains text to count elephants\"\n",
      "        },\n",
      "        \"case_sensitive\": {\n",
      "          \"type\": \"boolean\",\n",
      "          \"description\": \"True if user specifies he want to counts only SMALL or BIG elephants or if he expectly mentiond it should be case sensitive\"\n",
      "        },\n",
      "        \"output_format\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"num (if user ask for counting elephants) text (if user ask to tell him how many elephants)\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"some_str\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "def count_elephants(some_str: str, case_sensitive: bool = False, output_format:str = \"num\") -> object:\n",
    "    \"\"\"Counts elephants in some text provided by user\n",
    "\n",
    "    Args:\n",
    "        some_str: Extracted part of user message that contains text to count elephants\n",
    "        case_sensitive: True if user specifies he want to counts only SMALL or BIG elephants or if he expectly mentiond it should be case sensitive\n",
    "        output_format: num (if user ask for counting elephants) text (if user ask to tell him how many elephants)\n",
    "    \"\"\"\n",
    "    if not case_sensitive:\n",
    "        some_str = some_str.lower()\n",
    "    cnt = len(some_str.split(\"elephant\"))-1\n",
    "    if output_format == \"num\": \n",
    "        return cnt\n",
    "    else:\n",
    "        return f\"Number of elephants is {cnt}\"\n",
    "\n",
    "function_schema = convert_to_openai_tool(count_elephants)\n",
    "print(json.dumps(function_schema, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"\",\n",
      "    \"additional_kwargs\": {\n",
      "        \"function_call\": {\n",
      "            \"arguments\": \"{\\n\\\"some_str\\\": \\\"Elephants? I love elephants! Elephants are fucking amazing!\\\"\\n}\",\n",
      "            \"name\": \"count_elephants\"\n",
      "        }\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 20,\n",
      "            \"prompt_tokens\": 151,\n",
      "            \"total_tokens\": 171\n",
      "        },\n",
      "        \"model_name\": \"gpt-4-0613\",\n",
      "        \"system_fingerprint\": null,\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run-46129101-11ac-4b07-b71b-7a92217ceb9b-0\",\n",
      "    \"example\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_with_functions = ChatOpenAI(\n",
    "    model_name=\"gpt-4-0613\",\n",
    "    model_kwargs={\n",
    "        \"functions\": [function_schema['function']],\n",
    "        \"function_call\": {\"name\": \"count_elephants\"}, \n",
    "    }\n",
    ")\n",
    "\n",
    "import json\n",
    "result = model_with_functions.invoke([HumanMessage(content='Please, count elephants in the text \"Elephants? I love elephants! Elephants are fucking amazing!')])\n",
    "print(json.dumps(json.loads(result.json()), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
