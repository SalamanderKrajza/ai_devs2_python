{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function calling\n",
    "#### **General idea**\n",
    "Let LLM know how to prepare its output so it can be used by your functions\n",
    "\n",
    "\n",
    "#### **Explanation**\n",
    "LLM can't execute any functions by itself, but if its object is initialized in right way it may\n",
    "1. Get list of functions that may be executed with his output\n",
    "2. Get list of desired input for each function\n",
    "3. Choose which function from your list is best fit to your prompt\n",
    "4. Prepare its result in json fromat that may be passed to function later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets start with some smple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of elephants is 1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_elephants(some_str, case_sensitive=False, output_format=\"num\"):\n",
    "    \"\"\"\n",
    "    It counts ELEPHANTS in given text\n",
    "    INPUTS:\n",
    "    some_str: str - text that we use to count elephants\n",
    "    case_sensitive: bool - \n",
    "    output_format: str - [\"num\", \"text]\" - to present implementation enum in function_calling\n",
    "    \"\"\"\n",
    "    if not case_sensitive:\n",
    "        some_str = some_str.lower()\n",
    "    cnt = len(some_str.split(\"elephant\"))-1\n",
    "    if output_format == \"num\": \n",
    "        return cnt\n",
    "    else:\n",
    "        return f\"Number of elephants is {cnt}\"\n",
    "\n",
    "count_elephants(\n",
    "    \"In this text we have John - The BIG ELEPHANT, and Susan, the little elephant\", \n",
    "    case_sensitive=True, output_format=\"text\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing function schema and passing it to LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_elephants_schema = {\n",
    "    \"name\": \"count_elephants\",\n",
    "    \"description\": \"Counts elephants in some text provided by user\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"some_str\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"Extracted part of user message that contains text to count elephants\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            \"case_sensitive\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"True if user specifies he want to counts only SMALL or BIG elephants or if he expectly mentiond it should be case sensitive\"\n",
    "            },\n",
    "            \"output_format\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"num (if user ask for counting elephants) text (if user ask to tell him how many elephants)\",\n",
    "                \"enum\": [\"num\", \"text\"]\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"type\", \"tags\", \"command\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**initialization model with funcitons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# WITHOUT FUNCTION_CALL SPECIFIED (which indicates default function)\n",
    "# --------------------------------------------------------------\n",
    "# Model will respond normally (without functions) unless function use would be obvvious\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "model_with_functions = ChatOpenAI(\n",
    "    model_name=\"gpt-4-0613\",\n",
    "    model_kwargs={\n",
    "        \"functions\": [count_elephants_schema]\n",
    "        # \"function_call\": {\"name\": \"query_enrichment\"}, \n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_with_functions response for non-related to elephants stuff (no function_call specified)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"Hello! How can I assist you today?\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 10,\n",
      "            \"prompt_tokens\": 131,\n",
      "            \"total_tokens\": 141\n",
      "        },\n",
      "        \"model_name\": \"gpt-4-0613\",\n",
      "        \"system_fingerprint\": null,\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run-cf74bc71-ca8a-4723-929a-abcca481301f-0\",\n",
      "    \"example\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "result = model_with_functions.invoke([HumanMessage(content=\"Hey there!\")])\n",
    "print(json.dumps(json.loads(result.json()), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_with_functions response for asking to count elephants (no function_call specified)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"\",\n",
      "    \"additional_kwargs\": {\n",
      "        \"function_call\": {\n",
      "            \"arguments\": \"{\\n  \\\"some_str\\\": [\\\"Elephants? I love elephants! Elephants are fucking amazing!\\\"],\\n  \\\"output_format\\\": \\\"text\\\"\\n}\",\n",
      "            \"name\": \"count_elephants\"\n",
      "        }\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 37,\n",
      "            \"prompt_tokens\": 149,\n",
      "            \"total_tokens\": 186\n",
      "        },\n",
      "        \"model_name\": \"gpt-4-0613\",\n",
      "        \"system_fingerprint\": null,\n",
      "        \"finish_reason\": \"function_call\",\n",
      "        \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run-4d639074-52bd-4db7-a157-37611146db34-0\",\n",
      "    \"example\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "result = model_with_functions.invoke(\n",
    "    [\n",
    "        HumanMessage(content='Please, count elephants in the text \"Elephants? I love elephants! Elephants are fucking amazing!')\n",
    "    ]\n",
    ")\n",
    "print(json.dumps(json.loads(result.json()), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_with_functions response for non-related to elephants stuff (WITH function_call specified)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"\",\n",
      "    \"additional_kwargs\": {\n",
      "        \"function_call\": {\n",
      "            \"arguments\": \"{\\n  \\\"some_str\\\": [\\\"Hey there!\\\"]\\n}\",\n",
      "            \"name\": \"count_elephants\"\n",
      "        }\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 12,\n",
      "            \"prompt_tokens\": 138,\n",
      "            \"total_tokens\": 150\n",
      "        },\n",
      "        \"model_name\": \"gpt-4-0613\",\n",
      "        \"system_fingerprint\": null,\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run-0b9dd49b-edb8-498c-a024-bd6693887832-0\",\n",
      "    \"example\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# WITH FUNCTION_CALL SPECIFIED (default = count_elaphants)\n",
    "# --------------------------------------------------------------\n",
    "# (model will choose this if context not suggest any other from list)\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_with_functions = ChatOpenAI(\n",
    "    model_name=\"gpt-4-0613\",\n",
    "    model_kwargs={\n",
    "        \"functions\": [count_elephants_schema],\n",
    "        \"function_call\": {\"name\": \"count_elephants\"}, \n",
    "    }\n",
    ")\n",
    "\n",
    "import json\n",
    "result = model_with_functions.invoke([HumanMessage(content=\"Hey there!\")])\n",
    "print(json.dumps(json.loads(result.json()), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using python BaseModel and pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining pydantic BaseModel to let LLM know about structure**\n",
    "\n",
    "```\n",
    "NOTE: There is STR value in output_format instead of ENUM. \n",
    "Using ENUM here requires Enum library and defining new class\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CountElephantsInput(BaseModel):\n",
    "    some_str: str = Field(..., description=\"Extracted part of user message that contains text to count elephants\")\n",
    "    case_sensitive: bool = Field(False, description=\"True if user specifies he want to counts only SMALL or BIG elephants or if he expectly mentiond it should be case sensitive\")\n",
    "    output_format: str = Field(\"num\", description=\"num (if user ask for counting elephants) text (if user ask to tell him how many elephants)\")\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"some_str\": \"There are 5 elephants in the room, and 2 more elephants just entered.\",\n",
    "                \"case_sensitive\": False,\n",
    "                \"output_format\": \"text\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize model with functions schema defined with pydantic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChatOpenAI with the bound function\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4-0613\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "model_with_functions_pydantic = model.bind_functions(\n",
    "    functions=[CountElephantsInput],\n",
    "    function_call={\"name\": \"CountElephantsInput\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_with_functions_pydantic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"\",\n",
      "    \"additional_kwargs\": {\n",
      "        \"function_call\": {\n",
      "            \"arguments\": \"{\\n  \\\"some_str\\\": \\\"this is elephant, this is another elephant so we have two of them, right?\\\"\\n}\",\n",
      "            \"name\": \"CountElephantsInput\"\n",
      "        }\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 25,\n",
      "            \"prompt_tokens\": 161,\n",
      "            \"total_tokens\": 186\n",
      "        },\n",
      "        \"model_name\": \"gpt-4-0613\",\n",
      "        \"system_fingerprint\": null,\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run-c830ca64-69ab-4ce5-ade5-b228d3c3ca74-0\",\n",
      "    \"example\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hey there! Lets count elephants in just single example: 'this is elephant, this is another elephant so we have two of them, right?'\"\n",
    "result = model_with_functions_pydantic.invoke([HumanMessage(content=user_input)])\n",
    "print(json.dumps(json.loads(result.json()), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROS OF PYDANTIC - we can easly test model outpus against defined class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountElephantsInput\n",
      "{\n",
      "  \"some_str\": \"this is elephant, this is another elephant so we have two of them, right?\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountElephantsInput(some_str='this is elephant, this is another elephant so we have two of them, right?', case_sensitive=False, output_format='num')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets take previous example function args\n",
    "function_name = result.additional_kwargs[\"function_call\"][\"name\"]\n",
    "print(function_name)\n",
    "\n",
    "function_args = result.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "print(function_args)\n",
    "\n",
    "# Lets validate&parse it\n",
    "validated_args = CountElephantsInput.parse_raw(function_args)\n",
    "validated_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"some_str\": \"Hey there!\", \"case_sensitive\": \"it should be boolean\"}\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for CountElephantsInput\ncase_sensitive\n  value could not be parsed to a boolean (type=type_error.bool)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39516/4228844251.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Lets validate&parse it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvalidated_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountElephantsInput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_valid_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mvalidated_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\salamander\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\main.cp310-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.parse_raw\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\salamander\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\main.cp310-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.parse_obj\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\salamander\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\main.cp310-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for CountElephantsInput\ncase_sensitive\n  value could not be parsed to a boolean (type=type_error.bool)"
     ]
    }
   ],
   "source": [
    "non_valid_args ='{\"some_str\": \"Hey there!\", \"case_sensitive\": \"it should be boolean\"}'\n",
    "print(non_valid_args)\n",
    "\n",
    "# Lets validate&parse it\n",
    "validated_args = CountElephantsInput.parse_raw(non_valid_args)\n",
    "validated_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountElephantsInput {\n",
      "    \"some_str\": \"this is elephant, this is another elephant so we have two of them, right?\",\n",
      "    \"case_sensitive\": false,\n",
      "    \"output_format\": \"num\"\n",
      "}\n",
      "\n",
      "\n",
      "Result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define list of functions available to model\n",
    "function_mapping = {'CountElephantsInput':count_elephants}\n",
    "\n",
    "# Our function have not defined validation inside it so lets assume we validate args before passing it\n",
    "# For this example i will pick values from Pydantic validation example\n",
    "function_name = function_name\n",
    "function_kwargs = validated_args.dict()\n",
    "print(function_name, json.dumps(function_kwargs,indent=4))\n",
    "\n",
    "# Execute function\n",
    "print(\"\\n\\nResult:\")\n",
    "function_mapping[function_name](**function_kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
